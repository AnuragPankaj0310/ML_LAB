{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7de7a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "# Drop Id column if present\n",
    "if \"Id\" in df.columns:\n",
    "    df = df.drop(\"Id\", axis=1)\n",
    "\n",
    "# Encode labels (Species -> 0,1,2)\n",
    "le = LabelEncoder()\n",
    "df[\"Species\"] = le.fit_transform(df[\"Species\"])\n",
    "\n",
    "X = df.drop(\"Species\", axis=1).values\n",
    "y = df[\"Species\"].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "labels = np.unique(y)\n",
    "class_names = le.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a50cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_smote(X, y, target_class, setting=\"random\", n_samples=20):\n",
    "    X_minority = X[y == target_class]\n",
    "    synthetic_samples = []\n",
    "\n",
    "    if setting == \"random\":\n",
    "        # (a) Random two-sample interpolation\n",
    "        for _ in range(n_samples):\n",
    "            i, j = np.random.choice(len(X_minority), 2, replace=False)\n",
    "            lam = np.random.rand()\n",
    "            x_new = lam * X_minority[i] + (1 - lam) * X_minority[j]\n",
    "            synthetic_samples.append(x_new)\n",
    "\n",
    "    elif setting == \"nearest\":\n",
    "        # (b) Nearest-neighbor interpolation\n",
    "        nn = NearestNeighbors(n_neighbors=2).fit(X_minority)\n",
    "        for i in range(len(X_minority)):\n",
    "            _, idx = nn.kneighbors([X_minority[i]])\n",
    "            j = idx[0][1]   # nearest neighbor\n",
    "            lam = np.random.rand()\n",
    "            x_new = lam * X_minority[i] + (1 - lam) * X_minority[j]\n",
    "            synthetic_samples.append(x_new)\n",
    "\n",
    "    synthetic_samples = np.array(synthetic_samples)\n",
    "    y_new = np.full(len(synthetic_samples), target_class)\n",
    "\n",
    "    X_resampled = np.vstack([X, synthetic_samples])\n",
    "    y_resampled = np.hstack([y, y_new])\n",
    "\n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0640bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_collect_preds(X_train, y_train, X_test, setting):\n",
    "    all_preds = np.zeros_like(y_test)\n",
    "\n",
    "    for cls in np.unique(y_train):\n",
    "        # Oversample this class\n",
    "        X_res, y_res = manual_smote(X_train, y_train, target_class=cls,\n",
    "                                    setting=setting, n_samples=30)\n",
    "\n",
    "        # Binary labels\n",
    "        y_train_binary = (y_res == cls).astype(int)\n",
    "\n",
    "        # Train linear regression\n",
    "        model = LinearRegression().fit(X_res, y_train_binary)\n",
    "\n",
    "        # Predict binary for this class\n",
    "        y_pred_binary = (model.predict(X_test) >= 0.5).astype(int)\n",
    "\n",
    "        # Assign class if predicted positive\n",
    "        for i in range(len(y_test)):\n",
    "            if y_pred_binary[i] == 1:\n",
    "                all_preds[i] = cls\n",
    "\n",
    "    return all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5507a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, pos_label=1):\n",
    "    tp = np.sum((y_true == pos_label) & (y_pred == pos_label))\n",
    "    fp = np.sum((y_true != pos_label) & (y_pred == pos_label))\n",
    "    fn = np.sum((y_true == pos_label) & (y_pred != pos_label))\n",
    "\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    rec  = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1   = (2 * prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "\n",
    "    return prec, rec, f1, tp, fp, fn\n",
    "\n",
    "def classification_report_manual(y_true, y_pred, labels, class_names):\n",
    "    report = {}\n",
    "    total_tp = total_fp = total_fn = 0\n",
    "    weighted_sum = 0\n",
    "    total_samples = len(y_true)\n",
    "\n",
    "    for cls, name in zip(labels, class_names):\n",
    "        prec, rec, f1, tp, fp, fn = compute_metrics((y_true==cls).astype(int),\n",
    "                                                    (y_pred==cls).astype(int))\n",
    "        support = np.sum(y_true==cls)\n",
    "        report[name] = {\"precision\": prec, \"recall\": rec, \"f1\": f1, \"support\": support}\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "        weighted_sum += f1 * support\n",
    "\n",
    "    # Macro, Micro, Weighted\n",
    "    macro_f1 = np.mean([v[\"f1\"] for v in report.values()])\n",
    "    micro_prec = total_tp / (total_tp + total_fp) if (total_tp+total_fp) > 0 else 0\n",
    "    micro_rec  = total_tp / (total_tp + total_fn) if (total_tp+total_fn) > 0 else 0\n",
    "    micro_f1   = (2 * micro_prec * micro_rec) / (micro_prec + micro_rec) if (micro_prec+micro_rec) > 0 else 0\n",
    "    weighted_f1 = weighted_sum / total_samples\n",
    "\n",
    "    return report, macro_f1, micro_f1, weighted_f1\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db9be423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RANDOM ===\n",
      "Accuracy: 0.8222222222222222\n",
      "Macro F1: 0.8114695340501793\n",
      "Micro F1: 0.8222222222222222\n",
      "Weighted F1: 0.8114695340501792 \n",
      "\n",
      "Per-Class Report:\n",
      "Iris-setosa     | Precision: 0.938 | Recall: 1.000 | F1: 0.968 | Support: 15\n",
      "Iris-versicolor | Precision: 0.889 | Recall: 0.533 | F1: 0.667 | Support: 15\n",
      "Iris-virginica  | Precision: 0.700 | Recall: 0.933 | F1: 0.800 | Support: 15\n",
      "\n",
      "=== NEAREST ===\n",
      "Accuracy: 0.8222222222222222\n",
      "Macro F1: 0.8114695340501793\n",
      "Micro F1: 0.8222222222222222\n",
      "Weighted F1: 0.8114695340501792 \n",
      "\n",
      "Per-Class Report:\n",
      "Iris-setosa     | Precision: 0.938 | Recall: 1.000 | F1: 0.968 | Support: 15\n",
      "Iris-versicolor | Precision: 0.889 | Recall: 0.533 | F1: 0.667 | Support: 15\n",
      "Iris-virginica  | Precision: 0.700 | Recall: 0.933 | F1: 0.800 | Support: 15\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(setting_name):\n",
    "    print(f\"\\n=== {setting_name.upper()} ===\")\n",
    "    y_pred = train_and_collect_preds(X_train, y_train, X_test, setting_name)\n",
    "\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "    report, macro_f1, micro_f1, weighted_f1 = classification_report_manual(\n",
    "        y_test, y_pred, labels, class_names\n",
    "    )\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Macro F1:\", macro_f1)\n",
    "    print(\"Micro F1:\", micro_f1)\n",
    "    print(\"Weighted F1:\", weighted_f1, \"\\n\")\n",
    "\n",
    "    print(\"Per-Class Report:\")\n",
    "    for cls, metrics in report.items():\n",
    "        print(f\"{cls:15s} | \"\n",
    "              f\"Precision: {metrics['precision']:.3f} | \"\n",
    "              f\"Recall: {metrics['recall']:.3f} | \"\n",
    "              f\"F1: {metrics['f1']:.3f} | \"\n",
    "              f\"Support: {metrics['support']}\")\n",
    "\n",
    "# Run both SMOTE settings\n",
    "run_experiment(\"random\")\n",
    "run_experiment(\"nearest\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
